
\begin{frame}
\center \huge \scshape Overfitting
\end{frame}

\begin{frame}
\center
\textbf{Example:}
\\
We want to learn the model that generated some training data:\\
\begin{table}[h]
\begin{tabular}{c}
\multicolumn{1}{l}{\textbf{Training data}} \\ \hline
\multicolumn{1}{|c|}{2135}    \\ \hline
\multicolumn{1}{|c|}{4313}    \\ \hline
\multicolumn{1}{|c|}{1325}    \\ \hline
\multicolumn{1}{|c|}{2213}    \\ \hline
\multicolumn{1}{|c|}{4133}    \\ \hline
\end{tabular}
\end{table}
\end{frame}

\begin{frame}
\begin{table}[h]
\begin{tabular}{c}
\multicolumn{1}{l}{\textbf{Learned model}} \\ \hline
\multicolumn{1}{|c|}{2135}    \\ \hline
\multicolumn{1}{|c|}{4313}    \\ \hline
\multicolumn{1}{|c|}{2135}    \\ \hline
\multicolumn{1}{|c|}{2213}    \\ \hline
\multicolumn{1}{|c|}{4133}    \\ \hline
\end{tabular}
\end{table}
\end{frame}

\begin{frame}
\begin{table}[h]
\begin{tabular}{c}
\multicolumn{1}{l}{\textbf{Learned model}} \\ \hline
\multicolumn{1}{|c|}{2, 2135}    \\ \hline
\multicolumn{1}{|c|}{1, 4313}    \\ \hline
\multicolumn{1}{|c|}{1, 2213}    \\ \hline
\multicolumn{1}{|c|}{1, 4133}    \\ \hline
\end{tabular}
\end{table}
\center
LL of training data: $\sum_O log \; P(O\;|\;\lambda)$
\end{frame}

\begin{frame}
What about other data generated by the model?
\begin{table}[h]
\begin{tabular}{cc}
\textbf{New sequences}     & \multicolumn{1}{l}{\textbf{Learned model}} \\ \hline
\multicolumn{1}{|c|}{4135} & \multicolumn{1}{c|}{2, 2135}                  \\ \hline
\multicolumn{1}{|c|}{1322} & \multicolumn{1}{c|}{1, 4313}                  \\ \hline
\multicolumn{1}{|c|}{4213} & \multicolumn{1}{c|}{1, 2213}                  \\ \hline
\multicolumn{1}{|c|}{5135} & \multicolumn{1}{c|}{1, 4133}                  \\ \hline
\multicolumn{1}{|c|}{1345} & 	\multicolumn{1}{c|}{}						                \\ \hline
\end{tabular}
\end{table}
LL of new data?
\begin{itemize}
\item $0$?
\end{itemize}
\end{frame}

\begin{frame}
When does overfitting happen?
\\
\begin{itemize}
\item Learning a too complex model
	\begin{itemize}
	\item Models all the noise
	\end{itemize}
\item Training data too little
	\begin{itemize}
	\item May not reflect model good enough
	\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\center
Assume a very general pattern exists:\\
\vspace{20pt}
\begin{tabular}{c}
\multicolumn{1}{l}{\textbf{Training data}} \\ \hline
\multicolumn{1}{|c|}{2\underline{13}5}    \\ \hline
\multicolumn{1}{|c|}{43\underline{13}}    \\ \hline
\multicolumn{1}{|c|}{\underline{13}25}    \\ \hline
\multicolumn{1}{|c|}{22\underline{13}}    \\ \hline
\multicolumn{1}{|c|}{4\underline{13}3}    \\ \hline
\end{tabular}
\end{frame}

\begin{frame}
\center
$1$ always followed by $3$:
\begin{figure}
\includegraphics[width=0.45\textwidth]{images/simplemodel.eps}
\end{figure}
\textbf{When learning a simple model:}
\begin{itemize}
\item Cannot express all noise
\item May benefit more from describing general patterns
\end{itemize}
\end{frame}

\begin{frame}
\center
\begin{figure}
\includegraphics[width=1\textwidth]{images/complexmodel.eps}
\end{figure}
\vspace{40pt}
\textbf{When learning a complex model:}\\
\begin{itemize}
\item May be able to describe all noise
  \begin{itemize}
  \item So why not do it?
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\center
How do we compare models / algorithms?
\begin{figure}
\includegraphics[width=0.7\textwidth]{images/validationdata.eps}
\end{figure}
\end{frame}

\begin{frame}
\center \huge \scshape Avoiding underflow
\end{frame}

\begin{frame}
\center
$P(X) = p_1p_2p_3p_4p_5p_6p_7p_8p_9\cdots$\\
\vspace{20pt}
$0 < p_x < 1$\\
\vspace{20pt}
Underflow when $P(X) = 0$

\end{frame}

\begin{frame}
Visual Studio, C\#: Double precision floating point
\begin{itemize}
\item $0.01^{200} = 0$
\item $0.02^{200} = 0$
\end{itemize}
Probability of a particular sequence can be very small:
\begin{itemize}
\item 23 symbols, uniformly distributed: $\frac{1}{23}^{238} = 0$
\item What about rare symbols?
\item What about probability of 1000 sequences?
\end{itemize}
\end{frame}

\begin{frame}
\center
Solution: Convert to log-space\\
$log \; (a \cdot b) = log \; a + log \; b$\\
\vspace{20pt}
Since $a < b \iff log \; a < log \; b$:\\
\vspace{20pt} 
We can often stay in Log-space
\end{frame}

\begin{frame}
\center
$log (0.01^{200}) = log \; 0.01 + log \; 0.01 + \cdots = -1381.55$\\
\vspace{20pt}
$log (0.02^{200}) = log \; 0.02 + log \; 0.02 + \cdots = -1173.60$
\end{frame}
