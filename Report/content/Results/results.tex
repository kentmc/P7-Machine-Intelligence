\chapter{Results}
\label{chap:results}
In the following, a number of tests are conducted to see how the algorithms described in chapter \ref{chap:models} would perform in the PautomaC competition. Tests are conducted on the three data sets, 6, 23, and 35. These data sets were chosen according to how well the algorithms proposed in this project performed in relation to \gls{bw}, such that \gls{bw} seems to loose on data set 6, be quite even on data set 23, and win on data set 35.
The perplexity measure described in section \ref{sec:pautomac} has then been used to evaluate a score.
Since the PautomaC competition allowed any number of submissions from the same contestant, each of the static algorithms can be tested with different number of states. The dynamic algorithms can be evaluated on each intermediate model that is produced while extending, which would also have been possible in the real competition.
However, one must note that the contestants did not receive precise feedback when submitting a solution. They only received their rank among other contestants. Therefore, it would be considered cheating if the parameters of the algorithms proposed in chapter \ref{chap:models} were changed, based on the score they receive according to the Pautomac evaluation criteria.

The parameters chosen for the following tests are all based on the outcome of the experiments described in chapter \ref{chap:experiments}.
For all tests, 5000 sequences from the Pautomac training data files have been used to learn the model. The static algorithms are run with different number of states, starting at 10 with a step size of 10.
The dynamic algorithms are run with 5 intermediate \gls{baum-welch} iterations.