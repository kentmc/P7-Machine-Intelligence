\section{Problem Definition}

The Baum Welch algorithm is the traditional choice for learning the parameters of a \gls{hmm}~\cite{pautomacTR}. 
For a number of iterations, the \gls{baum-welch} will by changing the parameters of a \gls{hmm} to increase the likelihood of the training data given the model. The algorithm only stops after a predefined number of iterations or when it has reached a predefined point of convergence.
A \gls{hmm} consists of a number of states connected by transitions. As seen in figure \ref{fig:bw-states-are-important}, the number of states chosen can affect the performance of \gls{baum-welch}. If one does not know the most suited number of states for the given problem, one may have to either choose a number of states arbitrarily, or perform tests using different number of states. If time is critical, the latter choice may not be possible.
The many data sets and solutions published during the Pautomac competition makes it easy to evaluate the performance of any proposed algorithm.
This naturally leads to our problem definition:

\begin{figure}
\begin{centering}
\begin{tikzpicture}
	\pgfplotsset{every axis legend/.append style={ 
		at={(0.5,1.03)},
		anchor=south}}
	\begin{axis}[
			xlabel = Number of states,
            	ylabel = Log likelihood,
            	legend columns=-1,
            	legend entries={Score}
			]
		\addplot+[mark=none]table[x=States, y=Score, col sep=tab]
		{content/Introduction/bw-states-are-important.csv};
	\end{axis}
\end{tikzpicture}
\caption{Using the \gls{baum-welch} to learn the parameters of \gls{hmm}s with different number of states, based on the 1st data set of the Pautomac competition.}
\label{fig:bw-states-are-important} 
\end{centering}
\end{figure}


\paragraph{Problem:}
Based on the Pautomac competition data, how can we use learn the probabilistic parameters as well as the structure of a \gls{hmm}.