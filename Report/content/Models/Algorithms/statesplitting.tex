\subsection{State Splitting Approach}

Another dynamic size \gls{hmm} learning approach was to construct a greedy heuristics to ``split'' states. Several versions and concepts were attempted whilst maintaining the \gls{baum-welch} as a basis for the approach, running it repeatedly on the growing model to ensure convergence. The initial experiments were splitting states until a given number of states ($n$) was reached, but a threshold ($\theta$) mechanic was employed at a later time in attempt to reduce the dependency on the prior knowledge of number of states.

The greedy state splitting algorithm consists of two main modules, with possible extensions. The main modules include the heuristics to identify the state (or multiple states) to split and the splitting algorithm itself. During the experiments, two additional concepts, not fundamental for the state splitting itself, were also explored - edge cutting and state removal.

\subsubsection{State Split Mechanics}
Two main approaches to splitting the states were considered for the state splitting algorithm. One being very simple, just producing a copy of the state to split (\emph{Clone split}) and a much more elaborate approach considering the topology of the state inside the hidden state graph (\emph{Distribution split}).

\paragraph{Clone Split}
As aforementioned the clone split simply creates an exact copy of the state to split. Two variations have been proposed for copying the state in regards to handling input transition probabilities. Either splitting the probability of reaching the original state in half between the original state and the clone or simply copying the probability of the original node to the clone and normalising the probabilities through all transition afterwards.

No significant difference in performance has been observed between the two very similar variations. For clarity the latter one is described more formally by the following procedure:
\begin{enumerate}
	\item For each state to split $w \in\mathcal{W}$ construct a new state $w'$ such that $w'\notin S$.
	\item Set the initial, transition and emission probabilities as well as incoming transitions of the new state to copy the original:
	$$\forall w\in\mathcal{W}: \pi_{w'} = \pi_w \wedge \forall s\in S: (a_{sw'} = a_{sw} \wedge a_{w's} = a_{ws}) \wedge \forall \sigma\in\Sigma: b_{w'}(\sigma)=b_w(\sigma)$$
	\item Normalise the initial probabilities:
	$$\forall s\in S: \pi_s = \frac{\pi_s}{\sum_{r\in S}\pi_r}$$
	\item Normalise the transition probabilities:
	$$\forall s,r\in S: a_{sr} = \frac{a_{sr}}{\sum_{p\in S}a_{sp}}$$
\end{enumerate}

The state $w'$ created by the above procedure will have exactly the same parameters as the original $w$. This in itself has proven to be a huge disadvantage of the \emph{Clone split} methods as the \gls{baum-welch} was unable to distinguish between the two states and thus learn them to have different parameters. A possible solution would be to randomise part or all of the parameters of the newly created state $w'$, however this approach resembles the \hyperref[sec:greedy_extend]{Greedy Extend} very much and was thus not attempted.

The above described problem proved fatal for the \emph{Clone split} approach despite the attempts to alleviate it by incorporating other concepts such as edge cutting and state removal.

\paragraph{Distribution split}
\todo{Finish the state splitting section.}

\subsubsection{State Identification Heuristics}
Similarly to state splitting itself, two main approaches were explored for identifying the best state to split. The first one utilised the \gls{viterbi} thus named the \emph{Viterbi heuristic}, whilst the second one uses the $\gamma_t(i)$ variables computed during the \gls{baum-welch} and was therefore named the \emph{Gamma heuristic}.

Both of the heuristics compute a score $\zeta:S \rightarrow \mathbb{R}$ for each hidden state of the model, that can later be utilised to determine the state to split.

\paragraph{Viterbi Heuristic}
The \emph{Viterbi heuristic} computes the score $\zeta$ for each hidden state as a probability of producing the correct symbol in the validation sequences for which it belongs to the corresponding most probable hidden state sequence as determined by the \gls{viterbi}.

In more formal terms, the computation of the score $\zeta(s)$ for each $s \in S$ and a given \gls{hmm} $\lambda = (\mathbf{A}, \mathbf{B}, \boldsymbol{\pi})$ can be described by the following procedure:
\begin{enumerate}
	\item For each signal $\mathbf{O}\in D$ a corresponding most probable hidden state sequence is computed using the \gls{viterbi}: $\mathbf{Q}=\mathcal{V}_G(\mathbf{O})$.
	\item For each state $s\in S$ determine the significant positions in the hidden state sequences given by \gls{viterbi}:
	$$\forall s\in S,\forall \mathbf{O}=(o_1, ..., o_T)\in D: \tau_{s, \lambda}^\mathbf{O}=\{t\in\{1, ..., T\}|\mathbf{Q}_t=s\}$$
	\item For each state $s \in S$  and $\mathbf{O}\in D$ compute the partial score (performance) $\hat\zeta_{\mathbf{O}}(s)$ as the average probability of producing the expected observable symbol in accordance to the signal $\mathbf{O}$ over all the significant positions for the given state $s$ and signal $\mathbf{O}$:
	$$\forall s\in S,\forall \mathbf{O}\in D: \hat{\zeta}_{\mathbf{O}}(s) = \frac{\sum_{t\in\tau_{s, \lambda}^{\mathbf{O}}}b_s(o_t)}{|\tau_{s, \lambda}^{\mathbf{O}}|}$$
	\item Finally, compute the $\zeta$ score for each state $s\in S$ as a sum of all the partial scores for the given state weighted by the probabilities of generating the associated signals by the corresponding hidden state sequences:
	$$\forall s\in S: \zeta(s)=\sum_{\mathbf{O}\in D}P(\mathbf{Q}|\mathbf{O}, \lambda)\hat\zeta_{s, \lambda}^{\mathbf{O}}$$
\end{enumerate}

The obtained $\zeta$ scores the states of the \gls{hmm} based on their ``performance'' for the tasks they are most likely to perform. As such the state with the lowest score is determined to be the worst performing node $w$: $$w = \argmin_{s\in S}(\zeta(s))$$

This node is deemed to be the worst performing one as a result of being involved in the generation of many of the signals in the validation set $V$. As such, it seems meaningful to split the node into two, in order to share the extensive workload and increase performance.

The \emph{Viterbi heuristic} can be straightforwardly extended to identify more than just one state to split, thereby producing a set of the worst performing nodes $\mathcal{W}$. The set can be constructed iteratively starting with $\mathcal{W} = \emptyset$ as:

$$\mathcal{W} = \mathcal{W} \cup \{\argmin_{s\in S\setminus \mathcal{W}}(\zeta(s))\}$$
until $|\mathcal{W}|$ equals the desired number of states to split.

A further modification of the \emph{Viterbi heuristic} was considered to incorporate the use of a splitting threshold $\theta$ instead of a maximum number of states. For this purpose a normalised version of the score $\overline{\zeta}$ was introduced:
$$\overline{\zeta}(s) = \frac{\zeta(s)}{\sum_{s\in S}\zeta(s)}$$

The states to split $\mathcal{W}$ were thus determined as all states that scored below the given threshold $\theta$:
$$\mathcal{W} = \{s\in S|\overline\zeta(s) < \theta\}$$

More improvements to the \emph{Viterbi heuristic} were considered, mainly including the \emph{n-step Viterbi heuristic} that would have computed the score on not only the output probability in the given significant position, but also on the probability of correctly outputting the next $n -1$ symbols of the given signal - starting from the explored state - to further increase precision. The above described version of the \emph{Viterbi heuristic} would be considered \emph{1-step Viterbi heuristic} in this context. This approach however remains untested due to preference of the \emph{Gamma heuristic} and can be considered for future work.

\paragraph{Gamma Heurisitic}
\todo{Write the gamma splitting.}

\subsubsection{Edge Cutting}
In attempt to induce a data derived sparsity into the model while using the \emph{Clone split} an approach of cutting unsaturated edges from the model has been devised. The concept of cutting in this context means setting the transition probability to $0$.

Two different methods of cutting edges had been tested. The first one labeled as ``strict'' kept a constant out (in) degrees for the nodes and a different ``unconstrained'' edge cutting approach that was forcing transition probability to zero once it dropped below a certain threshold.

\paragraph {Strict Edge Cutting}
The strict edge cutting method was motivated by lowering the computational complexity of the \gls{baum-welch} algorithm. As the \gls{baum-welch} runs with the complexity $\mathcal{O}(Tn^2+Tnm)$ where $n$ is the number of states $m$ is the number of symbols and $T$ is the length of the training sequence, we attempted to lower the complexity to simply $\mathcal{O}(Tnm)$. As such an upper bound of $m$ has been placed on the out degree of all the states: $$\forall s\in S: d^-(s) \le m$$ where the $d^-(s)$ is the out degree of the node $s$ in the sense of number of non-zero out-transitions of the node $s$.

The edge cutting occurs immediately after splitting states includes a breach of the above property.

%This algorithm utilises a greedy concept to grow the hidden state space of a \gls{hmm} whilst maintaining a sparse transition matrix to preserve computability in large state spaces. The Greedy %State Splitting relies heavily on the existing \gls{baum-welch} calling it repeatedly to achieve convergence.

%Let $(n, s, \epsilon, D, V)$ be the input vector of the Greedy State Splitting algorithm where: $n, s \in \mathbb{N}, \epsilon\in[0,1], D$ is the training data set and $V$ is the validation data %set. The greedy State Splitting algorithm starts with two vertex complete graph $G=K_2$ for the hidden state space with all the parameters randomised. Afterwards it iterates through the %following phases until $|V(G)| = n$:

%\begin{itemize}
%	\item[] Phase 1, state splitting
%	\item[1)] For each observable state sequence $\mathbf{O} \in V$ a corresponding most probable hidden state sequence is computed using \gls{viterbi}: %$\mathbf{Q}=\mathcal{V}_G(\mathbf{O})$.
%	\item[2)] For each vertex $v \in V(G)$ compute a score $s(v)$ as the probability the given vertex outputs the desired output symbol according to the precomputed hidden state %sequences weighted by the probability of these sequences. In more formal terms, let $\theta_G(\mathbf{O}=(o_1,...,o_T), v) = \{t\in\{1, ..., T\}|\mathbf{Q}_t=v\}$ then: $$s(v) = %\sum_{\mathbf{O}\in V}P(\mathbf{Q}|\mathbf{O},G) \frac{\sum_{t \in \theta_G(\mathbf{O}, v)}b_v(o_t)}{|\theta_G(\mathbf{O}, v)|}$$
%	\item[3)] Find the ``weakest'' vertex: $$w = \argmin_{v\in V(G)}\{s(v)\}$$.
%	\item[4)] Create a new graph $G' = G\cup \{w'\}$ where $w'$ is a new vertex such that: $\forall v\in V(G): a_{w'v} = a_{wv} \land a_{vw'} = a_{vw}$, $\forall \sigma \in \Sigma: %b_{w'}(\sigma) = b_w(\sigma)$ and $\pi(w') = \pi(w)$.
%	\item[5)] Normalise $G'$ so all the probabilities sum up to $1$.
%	\item[] Phase 2, edge cutting
%	\item[6)] For each edge $e = (v_1,v_2)\in E(G')$ check if the edge probability is lower then the given threshold: $a_{v-1,v_2}<\epsilon$. If so, remove the edge from the graph %($a_{v-1,v_2} = 0$).
%	\item[] Phase 3, re-estimation of the model parameters.
%	\item[7)] Run \gls{baum-welch} to re-learn the model parameters of the new model: $G = BW_t(G', D)$.
%\end{itemize}

%The algorithm has also been considered in a ``strict'' variation at first, where the edge cutting phase did not depend on the parameter $\epsilon$ but instead a constant out-degree was %maintained for all vertices, namely the size of the output symbol alphabet $s = |\Sigma|$. The early results however showed, that the strict out-degree variation is outperformed by the %$\epsilon$ threshold.