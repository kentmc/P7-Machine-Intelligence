\subsection{Greedy Extend}
\label{sec:greedy_extend}
Initially, a graph representation $G$ of a single state \gls{hmm} is created. The single node has the initial probability set to 1, loops to itself with probability 1, and its emission probabilities for each of the $m$ symbols are chosen randomly and normalised.

The following pseudo code describes how the algorithm continuously tries to extend the graph, as long as it improves the likelihood of the training data $D$:
\begin{enumerate}
\item Repeat until convergence:
	\item $G'$ = $(V(G) \cup \{y'\}, E(G))$, where $y'$ is a new node with a random initial probability, a random probability of transitioning to itself, and random emission probabilities for all $m$ symbols, normalised so they sum to $1$.
	\item Randomly choose a set of nodes $X'$ from $V(G')$, where $|A| = \lceil \log |V(G')| \rceil$.
	\item For each node $x \in X$, the transitions $(x, y')$ and $(y', x)$ are added to $E(G')$ with random transition probabilities.
	\item Normalize $G'$.
	\item If $LL(BW^{\beta}(G')) > LL(G)$, let $G = LL(BW^{\beta}(G'))$.
\end{enumerate}
where $BW^{\beta}(G')$ denotes the \gls{hmm} obtained by running \gls{bw} for $\beta$ iterations on $G$.

\paragraph{Measuring convergence}
Convergence can be measured based on the increase in log likelihood of the training data, in the same way as \gls{bw} uses a threshold of convergence.

\paragraph{Determining the $\beta$-value}
Another big question about the Greedy Extend algorithm, is how the choice of $\beta$ affects the performance of the algorithm.
As $\beta$ denotes the number of \gls{baum-welch} iterations to run each time the algorithm attempts to extend the graph, increasing $\beta$ will also increase the run time of the algorithm. It may be the case that better results are achieved when $\beta$ is increased, since more iterations of \gls{baum-welch} also means a greater increase in likelihood. However, it could be the case that using many iterations early increases the chance of getting trapped in a local optimum.
An experiment has been conducted where different values for $\beta$ are used on data set $23$ from the PautomaC competition. The results can be seen in figure \ref{fig:ge-different-thresholds-tested}. Each line represents the mean value of 5 runs of the Greedy Extend algorithm with the specified number of iterations. The plot for $\beta$-values of 0 and 1 does not include data up to all 100 states. This is because some of the 5 runs got stuck in a way such that 100 continuous attempts of extending the graph failed to increase the likelihood of the training data. Thus, the plot has been cut off at the largest amount of states all 5 runs have reached. 

\begin{figure}[!h]
\begin{centering}
\begin{tikzpicture}
	\pgfplotsset{every axis legend/.append style={ 
		at={(0.5,1.06)},
		anchor=south}}
	\begin{axis}[
			scale = 1.5,
			xlabel = Number of states,
            	ylabel = Log likelihood of validation data,
            	legend columns=-1,
            	legend entries={IT-0, IT-1, IT-2, IT-3, IT-5, IT-10, IT-25},
			legend style={/tikz/every even column/.append style={column sep=0.3cm}}]
		
		\addplot+[mark=none]table[x=States, y=IT-0, col sep=tab]
		{content/Experiments/graphdata/ge-intermediate-iterations-test.csv};
		
		\addplot+[mark=none]table[x=States, y=IT-1, col sep=tab]
		{content/Experiments/graphdata/ge-intermediate-iterations-test.csv};
		
		\addplot+[mark=none]table[x=States, y=IT-2, col sep=tab]
		{content/Experiments/graphdata/ge-intermediate-iterations-test.csv};
		
		\addplot+[mark=none]table[x=States, y=IT-3, col sep=tab]
		{content/Experiments/graphdata/ge-intermediate-iterations-test.csv};

		\addplot+[mark=none]table[x=States, y=IT-5, col sep=tab]
		{content/Experiments/graphdata/ge-intermediate-iterations-test.csv};
		
		\addplot+[mark=none]table[x=States, y=IT-10, col sep=tab]
		{content/Experiments/graphdata/ge-intermediate-iterations-test.csv};
		
		\addplot+[mark=none]table[x=States, y=IT-25, col sep=tab]
		{content/Experiments/graphdata/ge-intermediate-iterations-test.csv};
	\end{axis}
\end{tikzpicture}
\caption{Test of different $\beta$-values when running the Greedy Extend algorithm on data set 23.}
\label{fig:ge-different-thresholds-tested}
\end{centering}
\end{figure}

The test shown in figure \ref{fig:ge-different-thresholds-tested} indicates that using more iterations improves the result. However, initial experiments were conducted with different parameters, which indicated that anything above 5 iterations did not improve the result significantly. Therefore, $\beta = 5$ has been chosen as parameters for all further experiments.