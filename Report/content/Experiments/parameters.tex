\subsection{Experiment Parameters}
Each algorithm will be run on some step size between 1 and 100 states for its model. This number is simply selected by examining the models that originally generated each dataset. The maximum amount of states from a Pautomac model is 73 states. It is not certain that Baum-Welch, given 73 states as parameter, will reach an illustrative and representative result for a model of that size, which is why the maximum amount of states has been set to 100. It should be noted that 100 states might not be enough to reach a near optimal result.
The datasets given by Pautomac ranges in sequences. Some have 20.000 sequences while others have 100.000. These amounts of sequences are however larger than what is necessary to illustrate how one algorithm behaves, given some dataset. Another problem is that the larger datasets takes significantly longer to compute, compared to a subset of sequences. It is therefore interesting to explore what amount of sequences that will both produces useful results, without spending an unnecessary amount of time doing the computations.

\paragraph{Training Sequences}
There is at least 20,000 sequences in pautomac's training sets, which is much more than what is necessary to produce representative results for our models and algorithms. To determine some reasonable amount of training observations, we do a small experiment with \gls{baum-welch}, where a variable amount of sequences is used. Figure \ref{fig:sequences} shows that even 100 sequences will be enough for a representative result, as the logarithmic likelihood seem to change more from random local maxima, or a lucky pick of training sequences, than from the amount of sequences used for training. It was decided to use 5000 sequences as the running time for this amount was still reasonable. It should be noted that the running is increasing linearly with the amount of sequences used for training, whereas the running time increase quadratically by the number of states, following the complexity of the \gls{fb_algorithm} algorithm.

The setup for this experiment:
\begin{itemize}
\item Dataset: 36
\item Algorithm: Baum Welch
\item Threshold: 0.01
\item Training sequences: 100-50,000
\item Validation sequences: 1,000
\item CPU: 2 Ghz Intel core 2 duo
\end{itemize}

\begin{figure}
	\centering
	\begin{subfigure}[b]{0.5\textwidth}
        \begin{tikzpicture}
		\begin{axis}[
				scale = 0.9,
				ymin = 23000,
				ymax = 24000,
				ybar,
				xtick=data,
   				symbolic x coords={100,500,1000,5000,10000,50000},
				xlabel = Sequences,
            		ylabel = Score (lower is better)]
				\addplot+table[y=score, col sep=tab]
				{content/Experiments/graphdata/sequences.csv};
		\end{axis}%
	\end{tikzpicture}
        \end{subfigure}%
		\begin{subfigure}[b]{0.5\textwidth}
\begin{tikzpicture}
		\begin{axis}[
				scale = 0.9,
				ymin = 0,
				ybar,
				xtick=data,
   				symbolic x coords={100,500,1000,5000,10000,50000},
				xlabel = Sequences,
            		ylabel = Running time (seconds)]
				\addplot+table[y=time, col sep=tab]
				{content/Experiments/graphdata/sequences.csv};
		\end{axis}%
	\end{tikzpicture}
	\end{subfigure}
  	\caption{Plot of Baum-welch score and runningtime on different sequence amounts}\label{fig:sequences}
\end{figure}


\paragraph{Baum-Welch Treshold}
The Baum-Welch algorithm takes two parameters, the amount of states which the trained model should consist of and the threshold of convergence. The state range for the experiments have already been selected to range between 10 and 100 with a step size of 10. Unlike the choice of states, which is a variable, the threshold should be a static value for all the experiments.

Defining the threshold is done by exploring how Baum-Welch behaves on different threshold values. \ref{fig:threshold} shows the results from the experiments. Each threshold parameter value were combined with the parameter of 50 states, and trained on a single dataset.

\begin{figure}
\centering
	\begin{tikzpicture}
		\begin{axis}[
				ybar,
				xtick=data,
   				symbolic x coords={0.1,0.05,0.01,0.005,0.001,0.0001},
				xlabel = Treshold,
            		ylabel = Score (lower is better)]
				\addplot+table[y=Score, col sep=tab]
				{content/Experiments/graphdata/treshold.csv};
		\end{axis}
	\end{tikzpicture}
\caption{Loglikelyhood when running Baum-Welch with a treshold}
\label{fig:threshold}
\end{figure}

Based on the results, it is clear that a threshold of 0.01 will produce useful that are representative for much lower thresholds.

\subsection{Greedy Extend}
10 BW iterations between when after each extend.
100 attempts to extend graph.
0.01 threshold for BW when reaching a maximum of 100 states or if not able to expand further.

Whether we choose to run Greedy Extend a single or multiple times does not seem to have a big impact on the result.
In figure \ref{fig:ge-diversity-5-runs}, the result of 5 different runs of Greedy Extend can be seen. The results of all runs look very similar.
\begin{figure}
\begin{centering}
\begin{tikzpicture}
	\pgfplotsset{every axis legend/.append style={ 
		at={(0.5,1.03)},
		anchor=south}}
	\begin{axis}[
			xlabel = Number of states,
            	ylabel = Score (lower is better),
            	legend columns=-1,
            	legend entries={Run 1, Run 2, Run 3, Run 4, Run 5},
			legend style={/tikz/every even column/.append style={column sep=0.3cm}}]
		
		\addplot+[mark=none]table[x=States, y=Run1, col sep=tab]
		{content/Experiments/graphdata/ge-diversity-5-runs.csv};
		
		\addplot+[mark=none]table[x=States, y=Run2, col sep=tab]
		{content/Experiments/graphdata/ge-diversity-5-runs.csv};
		
		\addplot+[mark=none]table[x=States, y=Run3, col sep=tab]
		{content/Experiments/graphdata/ge-diversity-5-runs.csv};
		
		\addplot+[mark=none]table[x=States, y=Run4, col sep=tab]
		{content/Experiments/graphdata/ge-diversity-5-runs.csv};

		\addplot+[mark=none]table[x=States, y=Run5, col sep=tab]
		{content/Experiments/graphdata/ge-diversity-5-runs.csv};
	\end{axis}
\end{tikzpicture} 
\caption{5 different runs of Greedy Extend on the same data set using $\alpha = 100, \beta = 10$.}
\label{fig:ge-diversity-5-runs} 
\end{centering}
\end{figure}
