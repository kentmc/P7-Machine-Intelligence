\section{Experiment Parameters}\label{sec:parameters}
The learners introduced require a number of different input parameters. It is likely that different value for the parameters will affect the result. In the following, a number of experiments are conducted, aiming to find suitable parameters for all of the learners. 

\subsubsection{Static learners}
Since the static learners, namely \gls{bw} and \gls{sbw}, use a \gls{hmm} internally, the number of states of that \gls{hmm} is required as input.
The Pautomac models that generated the data sets were generated by at most 73 states, and due to the fact, that the computation effort increases quadratically with the number of states, we deem it unnecessary to test models with more than 100 states. Due to the large amount of time it takes to run the \gls{baum-welch}, a step size of 10 for the number of states tested.
The dynamic learners does not require a specified number of states, as they all start with a model containing just a single state, which in turns are extended.

The data sets given by Pautomac ranges in sequences. Some have 20.000 sequences while others have 100.000. These amounts of sequences are however larger than what is necessary to illustrate how one algorithm behaves, given some dataset. Another problem is that the larger datasets takes significantly longer to compute, compared to a subset of sequences. It is therefore interesting to explore what amount of sequences that will both produces useful results, without spending an unnecessary amount of time doing the computations.

\paragraph{Training Sequences}
The Pautomac training sets contain between 20,000 and 100,000 sequences.
An experiment has been conducted, to see whether all of these sequences are needed to learn a good model using \gls{baum-welch}.
The result is depicted in Figure \ref{fig:sequences}. It seems like it does not improve the result significantly when using more than 100 sequences.
However, it was decided to use 5000 sequences as the running time of \gls{baum-welch} for this amount is still reasonable. It should be noted that the running time increases linearly with the amount of sequences used for training, but quadratically by the number of states, following the complexity of the \gls{fb_algorithm} algorithm.

The setup for this experiment:
\begin{itemize}
\item Dataset: 36
\item Algorithm: Baum Welch
\item Threshold: 0.01
\item Training sequences: 100-50,000
\item Validation sequences: 1,000
\item CPU: 2 Ghz Intel core 2 duo
\end{itemize}

\begin{figure}
	\centering
	\begin{subfigure}[b]{0.5\textwidth}
        \begin{tikzpicture}
		\begin{axis}[
				scale = 0.9,
			%	ymin = 23000,
			%	ymax = 24000,
	%			ybar,
				xtick=data,
   				symbolic x coords={100,500,1000,5000,10000,50000},
				xlabel = Sequences,
            		ylabel = Log likelihood]
				\addplot+table[y=score, col sep=tab]
				{content/Experiments/graphdata/sequences.csv};
		\end{axis}%
	\end{tikzpicture}
        \end{subfigure}%
		\begin{subfigure}[b]{0.5\textwidth}
\begin{tikzpicture}
		\begin{axis}[
				scale = 0.9,
	%			ymin = 0,
		%		ybar,
				xtick=data,
   				symbolic x coords={100,500,1000,5000,10000,50000},
				xlabel = Sequences,
            		ylabel = Running time (seconds)]
				\addplot+table[y=time, col sep=tab]
				{content/Experiments/graphdata/sequences.csv};
		\end{axis}%
	\end{tikzpicture}
	\end{subfigure}
  	\caption{Plot of Baum-welch score and runningtime on different sequence amounts}\label{fig:sequences}
\end{figure}


\paragraph{Baum-Welch Treshold}
The Baum-Welch algorithm takes two parameters, the amount of states which the trained model should consist of and the threshold of convergence. The state range for the experiments have already been selected to range between 10 and 100 with a step size of 10. Unlike the choice of states, which is a variable, the threshold should be a static value for all the experiments.

Defining the threshold is done by exploring how Baum-Welch behaves on different threshold values. \ref{fig:threshold} shows the results from the experiments. Each threshold parameter value were combined with the parameter of 50 states, and trained on a single dataset.

\begin{figure}
\centering
	\begin{tikzpicture}
		\begin{axis}[
			%	ybar,
				xtick=data,
   				symbolic x coords={0.1,0.05,0.01,0.005,0.001,0.0001},
				xlabel = Treshold,
            		ylabel = Log likelihood]
				\addplot+table[y=Score, col sep=tab]
				{content/Experiments/graphdata/treshold.csv};
		\end{axis}
	\end{tikzpicture}
\caption{Negative logarithmic likelihood when running Baum-Welch with different thresholds.}
\label{fig:threshold}
\end{figure}

The results show that a threshold below 0.01 does not improve the likelihood of the validation data significantly, thus a threshold of 0.01 will be used for future tests.

\subsubsection{Greedy Extend}
\label{sec:greedy}
\paragraph{Determining the $\beta$-value}
A big question about the Greedy Extend algorithm, is how the choice of the $\beta$-value affects the performance of the algorithm.
As $\beta$ denotes the number of \gls{baum-welch} iterations to run each time the algorithm attempts to extend the graph, increasing $\beta$ will also increase the run time of the algorithm. It may be the case that better results are achieved when $\beta$ is increased, since more iterations of \gls{baum-welch} also means a greater increase in likelihood. However, it could be the case that using many iterations early increases the chance of getting trapped in a local optimum.
An experiment has been conducted where different values for $\beta$ are used on data set $23$ from the PautomaC competition. The results can be seen in figure \ref{fig:ge-different-thresholds-tested}. Each line represents the mean value of 5 runs of the Greedy Extend algorithm with the specified number of iterations. The plot for $\beta$-values of 0 and 1 does not include data up to all 100 states. This is because some of the 5 runs got stuck in a way such that 100 continuous attempts of extending the graph failed to increase the likelihood of the training data. Thus, the plot has been cut off at the largest amount of states all 5 runs have reached. 

\begin{figure}[!h]
\begin{centering}
\begin{tikzpicture}
	\pgfplotsset{every axis legend/.append style={ 
		at={(0.5,1.06)},
		anchor=south}}
	\begin{axis}[
			scale = 1.5,
			xlabel = Number of states,
            	ylabel = Log likelihood of validation data,
            	legend columns=-1,
            	legend entries={IT-0, IT-1, IT-2, IT-3, IT-5, IT-10, IT-25},
			legend style={/tikz/every even column/.append style={column sep=0.3cm}}]
		
		\addplot+[mark=none]table[x=States, y=IT-0, col sep=tab]
		{content/Experiments/graphdata/ge-intermediate-iterations-test.csv};
		
		\addplot+[mark=none]table[x=States, y=IT-1, col sep=tab]
		{content/Experiments/graphdata/ge-intermediate-iterations-test.csv};
		
		\addplot+[mark=none]table[x=States, y=IT-2, col sep=tab]
		{content/Experiments/graphdata/ge-intermediate-iterations-test.csv};
		
		\addplot+[mark=none]table[x=States, y=IT-3, col sep=tab]
		{content/Experiments/graphdata/ge-intermediate-iterations-test.csv};

		\addplot+[mark=none]table[x=States, y=IT-5, col sep=tab]
		{content/Experiments/graphdata/ge-intermediate-iterations-test.csv};
		
		\addplot+[mark=none]table[x=States, y=IT-10, col sep=tab]
		{content/Experiments/graphdata/ge-intermediate-iterations-test.csv};
		
		\addplot+[mark=none]table[x=States, y=IT-25, col sep=tab]
		{content/Experiments/graphdata/ge-intermediate-iterations-test.csv};
	\end{axis}
\end{tikzpicture}
\caption{Test of different $\beta$-values when running \gls{ge} on data set 23.}
\label{fig:ge-different-thresholds-tested}
\end{centering}
\end{figure}

The test shown in figure \ref{fig:ge-different-thresholds-tested} indicates that using more iterations improves the result. However, initial experiments were conducted with different parameters, which indicated that anything above 5 iterations did not improve the result significantly. Therefore, $\beta = 5$ has been chosen as parameters for all further experiments.

Another experiment has been conducted to see how much the \gls{ge} is affected by random restarts.
In figure \ref{fig:ge-diversity-5-runs}, the result of 5 different runs of \gls{ge} can be seen.
The following parameters were used:
\begin{itemize}
\item Dataset: 23
\item $\beta$: 5
\item Training sequences: 5,000
\item Validation sequences: 5,000
\end{itemize}

\begin{figure}
\begin{centering}
\begin{tikzpicture}
	\pgfplotsset{every axis legend/.append style={ 
		at={(0.5,1.03)},
		anchor=south}}
	\begin{axis}[
			xlabel = Number of states,
            	ylabel = Log likelihood of validation data,
            	legend columns=-1,
			legend style={/tikz/every even column/.append style={column sep=0.3cm}}]
		
		\addplot+[mark=none]table[x=States, y=Run1, col sep=tab]
		{content/Experiments/graphdata/ge-diversity-5-runs.csv};
		
		\addplot+[mark=none]table[x=States, y=Run2, col sep=tab]
		{content/Experiments/graphdata/ge-diversity-5-runs.csv};
		
		\addplot+[mark=none]table[x=States, y=Run3, col sep=tab]
		{content/Experiments/graphdata/ge-diversity-5-runs.csv};
		
		\addplot+[mark=none]table[x=States, y=Run4, col sep=tab]
		{content/Experiments/graphdata/ge-diversity-5-runs.csv};

		\addplot+[mark=none]table[x=States, y=Run5, col sep=tab]
		{content/Experiments/graphdata/ge-diversity-5-runs.csv};
	\end{axis}
\end{tikzpicture} 
\caption{5 different runs of Greedy Extend on the same data set using $\beta = 5$.}
\label{fig:ge-diversity-5-runs} 
\end{centering}
\end{figure}
